{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Representation and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                                   Moran, Mr. James    male   NaN      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            330877   8.4583   NaN        Q  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data = pd.read_csv(os.path.join('data', 'Titanic_0.csv'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `titanic` dataset contains both categorical, text, and numeric features. We will use this dataset to predict whether a passenger survived the Titanic or not. \n",
    "\n",
    "Let's split the data into training and testing sets and use the `Survived` column as a target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Survived']\n",
    "X = data.drop(columns='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            141\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          549\n",
       "Embarked         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            108\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          411\n",
       "Embarked         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.Embarked.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>589</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>659</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>643</td>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>664</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex Embarked\n",
       "116    male        S\n",
       "131    male        S\n",
       "589  female        S\n",
       "27     male        S\n",
       "595    male        S\n",
       "..      ...      ...\n",
       "659  female        S\n",
       "256    male        S\n",
       "643    male        C\n",
       "249  female        C\n",
       "664  female        C\n",
       "\n",
       "[534 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['Sex', 'Embarked']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the classifiers are designed to work with numerical data. Therefore, we need to convert the categorical data into numeric features. The simplest way is to one-hot encode each categorical feature with the `OneHotEncoder`. Let's give an example for the `Sex` and `Embarked` columns. Note that we also encounter some data which are missing. We will use a `SimpleImputer` to replace the missing values with a constant values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., 0., 0., 0.],\n",
       "       [1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "ohe = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder())\n",
    "X_encoded = ohe.fit_transform(X_train[['Sex', 'Embarked']])\n",
    "X_encoded.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<534x6 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1068 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, it is possible to encode the categorical features. However, we also want to standardize the numerical features. Thus, we need to split the original data into 2 subgroups and apply a different preprocessing: (i) one-hot encoding for the categorical data and (ii) standard scaling for the numerical data. We also need to handle missing values in both cases. For the categorical column, we replace the missing values by the string `'missing_values'` which will be interpreted as a category on its own. For the numerical data, we will replace the missing data by the mean values of the feature of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_cat = ['Sex', 'Embarked']\n",
    "col_num = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "X_train_cat = X_train[col_cat]\n",
    "X_train_num = X_train[col_num]\n",
    "X_test_cat = X_test[col_cat]\n",
    "X_test_num = X_test[col_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_cat = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder())\n",
    "X_train_cat_enc = scaler_cat.fit_transform(X_train_cat)\n",
    "X_test_cat_enc = scaler_cat.transform(X_test_cat)\n",
    "\n",
    "scaler_num = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler())\n",
    "X_train_num_scaled = scaler_num.fit_transform(X_train_num)\n",
    "X_test_num_scaled = scaler_num.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<534x6 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1068 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.84978858,  0.42402614,  0.65645945,  0.06750954],\n",
       "       [-1.00181375, -0.48169369, -0.45639562, -0.46804832],\n",
       "       [ 1.35457638,  0.42402614,  2.88216959,  0.02222428],\n",
       "       ...,\n",
       "       [-2.26210241, -0.48169369,  0.65645945, -0.47082836],\n",
       "       [-0.92580117,  1.32974597,  1.76931452,  4.36960987],\n",
       "       [-1.15383892,  0.42402614, -0.45639562, -0.35761519]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should apply these transformations on the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "X_train_scaled = sparse.hstack((X_train_cat_enc,\n",
    "                                sparse.csr_matrix(X_train_num_scaled)))\n",
    "X_test_scaled = sparse.hstack((X_test_cat_enc,\n",
    "                               sparse.csr_matrix(X_test_num_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the transformation is done, we can combine the informations which are all numerical now. Finally, we use our `LogisticRegression` classifier as a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "accuracy = clf.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above pattern of first transforming the data and then fitting/scoring the classifier is exactly the one we saw before. Therefore, we would like to use a pipeline for such purpose. However, we would also like to have different processing on different columns of our matrix. The `ColumnTransformer` transformer or the `make_column_transformer` function should be used. It is used to automatically apply different pipeline on different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Pipeline is 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "pipe_cat = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder(handle_unknown='ignore'))\n",
    "pipe_num = make_pipeline(SimpleImputer(), StandardScaler())\n",
    "preprocessor = make_column_transformer((pipe_cat, col_cat), (pipe_num, col_num))\n",
    "\n",
    "pipe = make_pipeline(preprocessor, LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(pipe.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides, it can also be used in another pipeline. Thus, we will be able to use all `scikit-learn` utilities as `cross_validate` or `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('columntransformer',\n",
       "   ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                     transformer_weights=None,\n",
       "                     transformers=[('pipeline-1',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('simpleimputer',\n",
       "                                                     SimpleImputer(add_indicator=False,\n",
       "                                                                   copy=True,\n",
       "                                                                   fill_value=None,\n",
       "                                                                   missing_values=nan,\n",
       "                                                                   strategy='constant',\n",
       "                                                                   verbose=0)),\n",
       "                                                    ('onehotencoder',\n",
       "                                                     OneHotEncoder(categories='auto',\n",
       "                                                                   drop=None,\n",
       "                                                                   dtype=<class 'n...\n",
       "                                                                   sparse=True))],\n",
       "                                             verbose=False),\n",
       "                                    ['Sex', 'Embarked']),\n",
       "                                   ('pipeline-2',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('simpleimputer',\n",
       "                                                     SimpleImputer(add_indicator=False,\n",
       "                                                                   copy=True,\n",
       "                                                                   fill_value=None,\n",
       "                                                                   missing_values=nan,\n",
       "                                                                   strategy='mean',\n",
       "                                                                   verbose=0)),\n",
       "                                                    ('standardscaler',\n",
       "                                                     StandardScaler(copy=True,\n",
       "                                                                    with_mean=True,\n",
       "                                                                    with_std=True))],\n",
       "                                             verbose=False),\n",
       "                                    ['Age', 'SibSp', 'Parch', 'Fare'])],\n",
       "                     verbose=False)),\n",
       "  ('logisticregression',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                      intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                      multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                      random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                      warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'columntransformer': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                   transformer_weights=None,\n",
       "                   transformers=[('pipeline-1',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('simpleimputer',\n",
       "                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                 copy=True,\n",
       "                                                                 fill_value=None,\n",
       "                                                                 missing_values=nan,\n",
       "                                                                 strategy='constant',\n",
       "                                                                 verbose=0)),\n",
       "                                                  ('onehotencoder',\n",
       "                                                   OneHotEncoder(categories='auto',\n",
       "                                                                 drop=None,\n",
       "                                                                 dtype=<class 'n...\n",
       "                                                                 sparse=True))],\n",
       "                                           verbose=False),\n",
       "                                  ['Sex', 'Embarked']),\n",
       "                                 ('pipeline-2',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('simpleimputer',\n",
       "                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                 copy=True,\n",
       "                                                                 fill_value=None,\n",
       "                                                                 missing_values=nan,\n",
       "                                                                 strategy='mean',\n",
       "                                                                 verbose=0)),\n",
       "                                                  ('standardscaler',\n",
       "                                                   StandardScaler(copy=True,\n",
       "                                                                  with_mean=True,\n",
       "                                                                  with_std=True))],\n",
       "                                           verbose=False),\n",
       "                                  ['Age', 'SibSp', 'Parch', 'Fare'])],\n",
       "                   verbose=False),\n",
       " 'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'columntransformer__n_jobs': None,\n",
       " 'columntransformer__remainder': 'drop',\n",
       " 'columntransformer__sparse_threshold': 0.3,\n",
       " 'columntransformer__transformer_weights': None,\n",
       " 'columntransformer__transformers': [('pipeline-1', Pipeline(memory=None,\n",
       "            steps=[('simpleimputer',\n",
       "                    SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                                  missing_values=nan, strategy='constant',\n",
       "                                  verbose=0)),\n",
       "                   ('onehotencoder',\n",
       "                    OneHotEncoder(categories='auto', drop=None,\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  handle_unknown='ignore', sparse=True))],\n",
       "            verbose=False), ['Sex', 'Embarked']),\n",
       "  ('pipeline-2', Pipeline(memory=None,\n",
       "            steps=[('simpleimputer',\n",
       "                    SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                                  missing_values=nan, strategy='mean',\n",
       "                                  verbose=0)),\n",
       "                   ('standardscaler',\n",
       "                    StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "            verbose=False), ['Age', 'SibSp', 'Parch', 'Fare'])],\n",
       " 'columntransformer__verbose': False,\n",
       " 'columntransformer__pipeline-1': Pipeline(memory=None,\n",
       "          steps=[('simpleimputer',\n",
       "                  SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                                missing_values=nan, strategy='constant',\n",
       "                                verbose=0)),\n",
       "                 ('onehotencoder',\n",
       "                  OneHotEncoder(categories='auto', drop=None,\n",
       "                                dtype=<class 'numpy.float64'>,\n",
       "                                handle_unknown='ignore', sparse=True))],\n",
       "          verbose=False),\n",
       " 'columntransformer__pipeline-2': Pipeline(memory=None,\n",
       "          steps=[('simpleimputer',\n",
       "                  SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                                missing_values=nan, strategy='mean',\n",
       "                                verbose=0)),\n",
       "                 ('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "          verbose=False),\n",
       " 'columntransformer__pipeline-1__memory': None,\n",
       " 'columntransformer__pipeline-1__steps': [('simpleimputer',\n",
       "   SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                 missing_values=nan, strategy='constant', verbose=0)),\n",
       "  ('onehotencoder',\n",
       "   OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "                 handle_unknown='ignore', sparse=True))],\n",
       " 'columntransformer__pipeline-1__verbose': False,\n",
       " 'columntransformer__pipeline-1__simpleimputer': SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "               missing_values=nan, strategy='constant', verbose=0),\n",
       " 'columntransformer__pipeline-1__onehotencoder': OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "               handle_unknown='ignore', sparse=True),\n",
       " 'columntransformer__pipeline-1__simpleimputer__add_indicator': False,\n",
       " 'columntransformer__pipeline-1__simpleimputer__copy': True,\n",
       " 'columntransformer__pipeline-1__simpleimputer__fill_value': None,\n",
       " 'columntransformer__pipeline-1__simpleimputer__missing_values': nan,\n",
       " 'columntransformer__pipeline-1__simpleimputer__strategy': 'constant',\n",
       " 'columntransformer__pipeline-1__simpleimputer__verbose': 0,\n",
       " 'columntransformer__pipeline-1__onehotencoder__categories': 'auto',\n",
       " 'columntransformer__pipeline-1__onehotencoder__drop': None,\n",
       " 'columntransformer__pipeline-1__onehotencoder__dtype': numpy.float64,\n",
       " 'columntransformer__pipeline-1__onehotencoder__handle_unknown': 'ignore',\n",
       " 'columntransformer__pipeline-1__onehotencoder__sparse': True,\n",
       " 'columntransformer__pipeline-2__memory': None,\n",
       " 'columntransformer__pipeline-2__steps': [('simpleimputer',\n",
       "   SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                 missing_values=nan, strategy='mean', verbose=0)),\n",
       "  ('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'columntransformer__pipeline-2__verbose': False,\n",
       " 'columntransformer__pipeline-2__simpleimputer': SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "               missing_values=nan, strategy='mean', verbose=0),\n",
       " 'columntransformer__pipeline-2__standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'columntransformer__pipeline-2__simpleimputer__add_indicator': False,\n",
       " 'columntransformer__pipeline-2__simpleimputer__copy': True,\n",
       " 'columntransformer__pipeline-2__simpleimputer__fill_value': None,\n",
       " 'columntransformer__pipeline-2__simpleimputer__missing_values': nan,\n",
       " 'columntransformer__pipeline-2__simpleimputer__strategy': 'mean',\n",
       " 'columntransformer__pipeline-2__simpleimputer__verbose': 0,\n",
       " 'columntransformer__pipeline-2__standardscaler__copy': True,\n",
       " 'columntransformer__pipeline-2__standardscaler__with_mean': True,\n",
       " 'columntransformer__pipeline-2__standardscaler__with_std': True,\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__l1_ratio': None,\n",
       " 'logisticregression__max_iter': 100,\n",
       " 'logisticregression__multi_class': 'auto',\n",
       " 'logisticregression__n_jobs': None,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': None,\n",
       " 'logisticregression__solver': 'lbfgs',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14adbf57088>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "pipe_cat = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder(handle_unknown='ignore'))\n",
    "pipe_num = make_pipeline(StandardScaler(), SimpleImputer())\n",
    "preprocessor = make_column_transformer((pipe_cat, col_cat), (pipe_num, col_num))\n",
    "\n",
    "pipe = make_pipeline(preprocessor, LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "param_grid = {'columntransformer__pipeline-2__simpleimputer__strategy': ['mean', 'median'],\n",
    "              'logisticregression__C': [0.1, 1.0, 10]}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "scores = pd.DataFrame(cross_validate(grid, X, y, scoring='balanced_accuracy', cv=5, n_jobs=-1, return_train_score=True))\n",
    "scores[['train_score', 'test_score']].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.434805</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.768182</td>\n",
       "      <td>0.783283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.435803</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.777273</td>\n",
       "      <td>0.781211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.425828</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.769318</td>\n",
       "      <td>0.784378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.558012</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.783416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.443781</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.795034</td>\n",
       "      <td>0.772863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.434805    0.003989    0.768182     0.783283\n",
       "1  0.435803    0.002991    0.777273     0.781211\n",
       "2  0.425828    0.002992    0.769318     0.784378\n",
       "3  0.558012    0.004987    0.737374     0.783416\n",
       "4  0.443781    0.003989    0.795034     0.772863"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Do the following exercise:\n",
    "\n",
    "Load the adult dataset located in `./data/adult_openml.csv`. Make your own `ColumnTransformer` preprocessor. Pipeline it with a classifier. Fine tune it and check the prediction accuracy within a cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read the adult dataset located in `./data/adult_openml.csv` using `pd.read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(os.path.join('data', 'adult_openml.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capitalgain</th>\n",
       "      <th>capitalloss</th>\n",
       "      <th>hoursperweek</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0    2         State-gov   77516  Bachelors             13   \n",
       "1    3  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2    2           Private  215646    HS-grad              9   \n",
       "3    3           Private  234721       11th              7   \n",
       "4    1           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capitalgain  capitalloss  hoursperweek native-country  class  \n",
       "0            1            0             2  United-States  <=50K  \n",
       "1            0            0             0  United-States  <=50K  \n",
       "2            0            0             2  United-States  <=50K  \n",
       "3            0            0             2  United-States  <=50K  \n",
       "4            0            0             2           Cuba  <=50K  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the datasets into a data and a target. The target corresponds to the `class` column. For the data, drop the columns `fnlwgt`, `capitalgain`, and `capitalloss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = data2['class']\n",
    "X2 = data2.drop(columns=['class', 'fnlwgt', 'capitalgain', 'capitalloss'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The target is not encoded. Use the `sklearn.preprocessing.LabelEncoder` to encode the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y2 = encoder.fit_transform(y2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a list containing the name of the categorical columns. Similarly, do the same for the numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_cat = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'native-country', 'sex']\n",
    "col_num = ['age', 'hoursperweek']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a pipeline to one-hot encode the categorical data. Use the `KBinsDiscretizer` for the numerical data. Import it from `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "pipe_cat = OneHotEncoder(handle_unknown='ignore')\n",
    "pipe_num = KBinsDiscretizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a `preprocessor` by using the `make_column_transformer`. You should apply the right pipeline to the right column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "preprocessor = make_column_transformer((pipe_cat, col_cat), (pipe_num, col_num))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pipeline the preprocessor with a `LogisticRegression` classifier. Subsequently define a grid-search to find the best parameter `C`. Train and test this workflow in a cross-validation scheme using `cross_validate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14adc2f6648>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "pipe = make_pipeline(preprocessor, LogisticRegression(solver='lbfgs', max_iter=1000))\n",
    "param_grid = {'logisticregression__C': [0.1, 1.0, 10]}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "scores = pd.DataFrame(cross_validate(grid, X2, y2, scoring='balanced_accuracy', cv=3, n_jobs=-1, return_train_score=True))\n",
    "scores[['train_score', 'test_score']].boxplot(whis=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
